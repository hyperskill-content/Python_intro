{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG8CxJlidUSm"
   },
   "source": [
    "## Variables and basic types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT92Jq3_fMGk"
   },
   "source": [
    "### String formatting\n",
    "Python offers several ways to format strings. You'll use these constantly when building prompts, logging, and displaying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ns1ye8TZdSOL",
    "outputId": "d909f760-bacc-4ec5-cdbe-0584985931e2"
   },
   "outputs": [],
   "source": [
    "# F-strings\n",
    "provider = \"claude\"\n",
    "model = \"sonnet-4.5\"\n",
    "message = f\"Using {provider} with model {model}\"\n",
    "print(message)  # Using claude with model sonnet-4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tON-wh3Dfe8P",
    "outputId": "ae7a3f7e-0cd4-4ec4-aeb7-93f9372917ba"
   },
   "outputs": [],
   "source": [
    "# Multi-line f-strings, common for building prompts\n",
    "name = str(input(\"Give a cool name to your AI assistant: \"))\n",
    "user_input = str(input(\"Ask your AI assistant something: \"))\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant named {name}.\n",
    "Your task is to answer the following query:\n",
    "{user_input}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpdh1AAXdZLu"
   },
   "source": [
    "### Dictionaries and lists\n",
    "These structures map directly to JSON, which you'll use for API requests and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQ4YELgxgEtJ",
    "outputId": "ff4e4a23-9cc1-4e4e-b929-e01f081c8214"
   },
   "outputs": [],
   "source": [
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What is the weather today?\"\n",
    "}\n",
    "\n",
    "# Accessing values\n",
    "print(user_message[\"role\"])\n",
    "print(user_message.get(\"content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JpSCyLyNmmp",
    "outputId": "aea6ea72-fd4e-4593-b44e-b32dc7af4344"
   },
   "outputs": [],
   "source": [
    "# Nested dictionaries (common in API payloads)\n",
    "api_request = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "models = [\"gpt-4\", \"claude-3\", \"llama-2\"]\n",
    "print(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZEmaf0Mf7hm",
    "outputId": "376e273f-0c11-4060-a430-6b8b33fd7964"
   },
   "outputs": [],
   "source": [
    "# Adding items\n",
    "models.append(\"gemini-pro\")\n",
    "\n",
    "# Iterating\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pqyzF1fNx14"
   },
   "outputs": [],
   "source": [
    "# List of dictionaries (common pattern)\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hello! How can I help?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPeQaWlGdfDz"
   },
   "source": [
    "## Functions and control flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQJ_KgEHg1HQ"
   },
   "source": [
    "### Function definitions\n",
    "Functions in Python are straightforward. You'll write them to organize API calls, process responses, and build reusable logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "URsiuUwodjod",
    "outputId": "b3f2d099-2a7b-461d-ce9d-1f0ca186d929"
   },
   "outputs": [],
   "source": [
    "# Basic function\n",
    "def create_system_prompt(role: str) -> str: # role: str is a type hint for the input, the -> indicates the function return type\n",
    "    return f\"You are a {role}. Please assist the user.\"\n",
    "\n",
    "create_system_prompt(\"helpful assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rErgUrWLN2S2",
    "outputId": "ccd08867-7063-473f-fd49-8ad6325a842d"
   },
   "outputs": [],
   "source": [
    "# Function with multiple parameters and default values\n",
    "def call_llm(prompt: str, model: str = \"gpt-4\", temperature: float = 0.7) -> dict:\n",
    "    \"\"\"\n",
    "    Docstrings describe what the function does.\n",
    "    They're optional but helpful for complex functions.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "\n",
    "# Using the function\n",
    "response = call_llm(\"What is AI?\")  # uses defaults: model = \"gpt-4\", temperature = 0.7\n",
    "response = call_llm(\"What is AI?\", model=\"claude-3\", temperature=0.5)  # overrides defaults\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-ehT7RjN9_N",
    "outputId": "49dff0b9-d442-4a60-d365-69efb741b2dc"
   },
   "outputs": [],
   "source": [
    "mock_response = {\n",
    "  \"id\": \"chatcmpl-8x7k2Pm9qK3j5L8n4Yw6Xz\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1729512345,\n",
    "  \"model\": \"gpt-4\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hello! I'm an AI assistant. How can I help you today?\"\n",
    "      },\n",
    "      \"finish_reason\": \"stop\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 12,\n",
    "    \"completion_tokens\": 15,\n",
    "    \"total_tokens\": 27\n",
    "  }\n",
    "}\n",
    "\n",
    "# Functions can return multiple values (as a tuple)\n",
    "def parse_response(api_response: dict) -> tuple[str, int]:\n",
    "    content = api_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    tokens = api_response[\"usage\"][\"total_tokens\"]\n",
    "    return content, tokens\n",
    "\n",
    "# Unpacking the return values\n",
    "text, token_count = parse_response(mock_response)\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Tokens: {token_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhCSwV6dhE2H"
   },
   "source": [
    "### Conditional logic\n",
    "Use conditionals to handle different scenarios in your application logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "g9Agzo2UQxsT",
    "outputId": "ab19e424-2b95-4748-daaf-b8055137e096"
   },
   "outputs": [],
   "source": [
    "# Basic if/else\n",
    "def get_model_tier(model_name: str) -> str:\n",
    "    if model_name.startswith(\"gpt\"):\n",
    "        return \"premium\"\n",
    "    else:\n",
    "        return \"standard\"\n",
    "\n",
    "get_model_tier(\"gpt-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5t1TccgARGWW",
    "outputId": "130ea826-8f28-4695-9bb6-4ef22afac4bb"
   },
   "outputs": [],
   "source": [
    "# if/elif/else for multiple conditions\n",
    "def calculate_cost(tokens: int, model: str) -> float:\n",
    "    if model == \"gpt-4\":\n",
    "        rate = 0.03\n",
    "    elif model == \"gpt-3.5-turbo\":\n",
    "        rate = 0.002\n",
    "    elif model == \"claude-3\":\n",
    "        rate = 0.015\n",
    "    else:\n",
    "        rate = 0.001  # default rate\n",
    "\n",
    "    return tokens * rate / 1000\n",
    "\n",
    "calculate_cost(1000, \"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LrPYEsy3RJMB",
    "outputId": "5474e5c1-ec8b-4400-e666-fa2eb9708c01"
   },
   "outputs": [],
   "source": [
    "# Checking if values exist (common with API responses)\n",
    "def extract_content(response: dict) -> str:\n",
    "    if \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return \"No response available\"\n",
    "\n",
    "extract_content(mock_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kM1CkwJWS9Si",
    "outputId": "32bccac6-0eaf-48cb-9e3b-1b90dcfbab2f"
   },
   "outputs": [],
   "source": [
    "# Boolean conditions\n",
    "def should_retry(status_code: int, attempt: int) -> bool:\n",
    "    if status_code == 429 and attempt < 3:  # Rate limited, under retry limit\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "should_retry(429, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tk1waBsdnGh",
    "outputId": "1d4dd8e6-676b-4ef5-e02b-3eba161d4676"
   },
   "outputs": [],
   "source": [
    "response = {\n",
    "    \"status_code\": 200,\n",
    "    \"data\": {\"message\": \"Request successful\"}\n",
    "}\n",
    "# Ternary operator (inline if/else)\n",
    "status = \"success\" if response['status_code'] == 200 else \"error\"\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "u6J0NkDnTL7v",
    "outputId": "4625816c-8bc3-4c6f-90f1-0ec68a5d9507"
   },
   "outputs": [],
   "source": [
    "# Checking for None\n",
    "def process_data(data: dict | None) -> str:\n",
    "    if data is None:\n",
    "        return \"No data provided\"\n",
    "\n",
    "    return data.get(\"result\", \"No result found\")\n",
    "\n",
    "process_data({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOOiS8xjhYGs"
   },
   "source": [
    "### List comprehensions\n",
    "List comprehensions provide a concise way to transform and filter data. You'll use them frequently when processing API responses or preparing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Gy3uMItZinz",
    "outputId": "f0517d6c-38d1-4fb9-ce15-19bb592ac30e"
   },
   "outputs": [],
   "source": [
    "# Example: extracting specific fields\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"user\", \"content\": \"How are you?\"}\n",
    "]\n",
    "\n",
    "# Extract just the content from each message\n",
    "print([msg[\"content\"] for msg in messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CHgrldbZt9e",
    "outputId": "f2287088-75b8-4e97-b48d-575aca58abf6"
   },
   "outputs": [],
   "source": [
    "# List comprehension with filtering\n",
    "user_messages = [msg for msg in messages if msg[\"role\"] == \"user\"]\n",
    "\n",
    "print(user_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqC4pyYwZ8KF",
    "outputId": "54fdf9e5-723b-4eae-fc92-27b48a47f301"
   },
   "outputs": [],
   "source": [
    "# Transform and filter together\n",
    "user_contents = [msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\"]\n",
    "\n",
    "print(user_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZugZyuZaGk5",
    "outputId": "6b907cf5-6f4f-4d4f-a5e6-0ab7a08e4d58"
   },
   "outputs": [],
   "source": [
    "# Working with strings\n",
    "models = [\"gpt-4-turbo\", \"gpt-3.5-turbo\", \"claude-3-opus\"]\n",
    "\n",
    "gpt_models = [model for model in models if model.startswith(\"gpt\")]\n",
    "uppercase_models = [model.upper() for model in models]\n",
    "\n",
    "print(f\"GPT models: {gpt_models} \\nUppercase models: {uppercase_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GA5YqbPNa7A5",
    "outputId": "2d0979a3-25bf-480f-834d-508f95b592a3"
   },
   "outputs": [],
   "source": [
    "api_responses = [\n",
    "    {\"id\": 1, \"tokens\": 150, \"cost\": 0.003},\n",
    "    {\"id\": 2, \"tokens\": 200, \"cost\": 0.004},\n",
    "    {\"id\": 3, \"tokens\": 100, \"cost\": 0.002}\n",
    "]\n",
    "\n",
    "# Extract total tokens\n",
    "total_tokens = sum([resp[\"tokens\"] for resp in api_responses])\n",
    "\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4eNX8FgJauoD",
    "outputId": "b07994e6-8685-4b1d-bf86-e0be6af56c35"
   },
   "outputs": [],
   "source": [
    "# Create simplified objects\n",
    "summaries = [\n",
    "    {\"id\": resp[\"id\"], \"tokens\": resp[\"tokens\"]}\n",
    "    for resp in api_responses\n",
    "]\n",
    "\n",
    "print(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7_SULh8haPa",
    "outputId": "a987830c-42b2-4ef4-eec7-aa62c115af69"
   },
   "outputs": [],
   "source": [
    "# Dictionary comprehension. Convert list to dictionary\n",
    "token_map = {resp[\"id\"]: resp[\"tokens\"] for resp in api_responses}\n",
    "\n",
    "print(token_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JkbGDRodnZz"
   },
   "source": [
    "## Working with external libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSvuhEn4kxQz"
   },
   "source": [
    "### Installing packages\n",
    "Python's ecosystem relies on external packages. You can use any package present in the Python Package index (https://pypi.org/). \n",
    "You'll install them using `pip` (https://github.com/pypa/pip) or `uv` (https://github.com/astral-sh/uv). This setup already contains the `requests` library from the `requirements.txt` (you can inspect the Dockerfile for details on the installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQAmOGpbkxBh",
    "outputId": "b7b95b24-4020-4165-bf74-d64d48392375"
   },
   "outputs": [],
   "source": [
    "!uv pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gsb56W9adrSB"
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KX6BkSE5dxaz",
    "outputId": "072a7257-8d19-46d3-8512-8b132ddcb5ae"
   },
   "outputs": [],
   "source": [
    "# Make a GET request to a public API\n",
    "response = requests.get(\"https://api.github.com/users/github\")\n",
    "\n",
    "status = \"success\" if response.status_code == 200 else \"error\"\n",
    "\n",
    "print(f\"Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18Mw5IticEUQ",
    "outputId": "46fd3652-4c40-4681-be3e-71cf34913be6"
   },
   "outputs": [],
   "source": [
    "# Parse the JSON response\n",
    "if status == \"success\":\n",
    "    data = response.json()\n",
    "    print(f\"\\nUsername: {data['login']}\")\n",
    "    print(f\"Name: {data['name']}\")\n",
    "    print(f\"Public repos: {data['public_repos']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eJti318d4_3"
   },
   "source": [
    "## Intro to classes\n",
    "\n",
    "Classes let you create custom objects with their own data and behavior. You won't write many classes from scratch, but you'll use them constantly when working with objects provided by the external packages you import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0VFL7kuqC_W"
   },
   "source": [
    "### Basic class structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8fnZN-iZOJc"
   },
   "source": [
    "`__init__` sets up the object when you create it. Methods are functions that operate on the object's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEAVYBJUd9Yt"
   },
   "outputs": [],
   "source": [
    "# Define a class\n",
    "class ChatMessage:\n",
    "    def __init__(self, role: str, content: str):\n",
    "        \"\"\"__init__ runs when you create a new instance\"\"\"\n",
    "        self.role = role\n",
    "        self.content = content\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        \"\"\"Methods are functions that belong to the class\"\"\"\n",
    "        return {\n",
    "            \"role\": self.role,\n",
    "            \"content\": self.content\n",
    "        }\n",
    "\n",
    "    def is_user_message(self) -> bool:\n",
    "        return self.role == \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D41tlbPORg-Q",
    "outputId": "0e9388e4-263b-4109-e93d-8c2aa158ce3e"
   },
   "outputs": [],
   "source": [
    "# Create instances (objects) of the class\n",
    "msg1 = ChatMessage(role=\"user\", content=\"Hello\")\n",
    "msg2 = ChatMessage(role=\"assistant\", content=\"Hi there!\")\n",
    "\n",
    "# Access attributes\n",
    "print(msg1.role)\n",
    "print(msg1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qz08XxJvRk7B",
    "outputId": "30dfe58d-5ff9-48a5-c4d1-74c4fdb8344d"
   },
   "outputs": [],
   "source": [
    "# Call methods\n",
    "print(msg1.to_dict())\n",
    "print(msg1.is_user_message())\n",
    "print(msg2.is_user_message())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss_yLji4qBP-"
   },
   "source": [
    "### Example: Pydantic data models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq476IM1Y0uJ"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydantic classes validate data automatically\n",
    "class ChatRequest(BaseModel):\n",
    "    message: str\n",
    "    model: str = \"gpt-4\"\n",
    "    temperature: float = Field(default=0.7, ge=0, le=2)\n",
    "\n",
    "# Create instance - Pydantic validates the data\n",
    "request = ChatRequest(message=\"What is AI?\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kW-96vU1q1gA",
    "outputId": "68e2643f-f1ff-49b7-a76b-b7efa8d6d240"
   },
   "outputs": [],
   "source": [
    "# Access attributes\n",
    "print(request.message)\n",
    "print(request.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVpEoF1mZCMH",
    "outputId": "b6b6c275-8e06-4ea5-a04c-21818b768eca"
   },
   "outputs": [],
   "source": [
    "# Convert to dict (useful for API calls)\n",
    "print(request.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GslSE11rGtZ"
   },
   "source": [
    "In this course, you'll mostly use pre-built classes from libraries (Pydantic models, LangChain classes, etc.) rather than writing your own. Understanding how to create instances and call methods is what matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **decorator** is a function that modifies another function's behavior. The `@` symbol applies a decorator to the function below it. Here is an example of Pydantic decorators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "import requests\n",
    "\n",
    "class Post(BaseModel):\n",
    "    userId: int\n",
    "    id: int\n",
    "    title: str\n",
    "    body: str\n",
    "    \n",
    "    @field_validator('title')\n",
    "    @classmethod\n",
    "    def title_must_not_be_empty(cls, v):\n",
    "        if not v or not v.strip():\n",
    "            raise ValueError('Title cannot be empty')\n",
    "        return v\n",
    "    \n",
    "    @field_validator('userId')\n",
    "    @classmethod\n",
    "    def user_id_must_be_positive(cls, v):\n",
    "        if v <= 0:\n",
    "            raise ValueError('User ID must be positive')\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://jsonplaceholder.typicode.com/posts/1\")\n",
    "post = Post(**response.json()) \n",
    "\n",
    "print(f\"Validated post: {post.title}\")\n",
    "print(f\"User ID: {post.userId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, there are 2 decorators: `@field_validator` and `@classmethod`. Here is what each decorator does:\n",
    "\n",
    "1. `@classmethod` - Makes this a class method. Instead of operating on a specific instance of the class (which would use `self`), it operates on the class itself (using `cls`). This is required by Pydantic's validators.\n",
    "2. `@field_validator('title')` - Tells Pydantic: \"Run this function when validating the `title` field\"\n",
    "\n",
    "Validation happens here automatically: \n",
    "```python\n",
    "post = Post(**response.json()) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create a `Post` object, Pydantic:\n",
    "1. Checks the `title` field exists and is a string\n",
    "2. Runs `title_must_not_be_empty(cls, v)` where `v` is the title value\n",
    "3. If validation fails (raises `ValueError`), object creation fails\n",
    "4. If validation passes (returns `v`), the object is created\n",
    "\n",
    "The pattern:\n",
    "- `v` = the value being validated\n",
    "- Return `v` if valid (or a transformed version)\n",
    "- Raise `ValueError` if invalid\n",
    "\n",
    "Decorators are wrapping a function with extra behavior. Here, `@field_validator` wraps your validation function so Pydantic knows to call it automatically.\n",
    "\n",
    "You won't need to write them yourself, but you'll see them everywhere later in the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: GitHub repository analyzer   \n",
    "Core concepts needed: string formatting, dictionaries, lists, list comprehensions   \n",
    "\n",
    "Here is the utility function you can use during implementation:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# Utility function for implementation testing\n",
    "def fetch_github_user_repos(username: str, token: Optional[str] = None) -> list[dict]:\n",
    "    url = f\"https://api.github.com/users/{username}/repos\"\n",
    "    \n",
    "    headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n",
    "    if token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {token}\"\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    repos_data = response.json()\n",
    "    \n",
    "    simplified_repos = []\n",
    "    for repo in repos_data:\n",
    "        simplified_repos.append({\n",
    "            \"name\": repo.get(\"name\"),\n",
    "            \"description\": repo.get(\"description\"),\n",
    "            \"stars\": repo.get(\"stargazers_count\", 0),\n",
    "            \"forks\": repo.get(\"forks_count\", 0),\n",
    "            \"language\": repo.get(\"language\"),\n",
    "            \"url\": repo.get(\"html_url\"),\n",
    "            \"updated_at\": repo.get(\"updated_at\")\n",
    "        })\n",
    "    \n",
    "    return simplified_repos\n",
    "\n",
    "# Example usage: test_repos = fetch_github_user_repos(\"octocat\", token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the following functions to analyze GitHub repository data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_repo_summary(repo: dict) -> str:\n",
    "    \"\"\"\n",
    "    Format a repository summary string.\n",
    "    \n",
    "    Args:\n",
    "        repo: Dictionary with keys: name, description, stars, language, url\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string like:\n",
    "        \"repo-name (Language of the repo) - 1,234 ⭐ (should contain the star emoji)\n",
    "         Description here\n",
    "         https://github.com/user/repo\"\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def filter_repos_by_language(repos: list[dict], language: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Filter repositories by programming language.\n",
    "    \n",
    "    Args:\n",
    "        repos: List of repository dictionaries\n",
    "        language: Programming language to filter by (case-insensitive)\n",
    "    \n",
    "    Returns:\n",
    "        Filtered list of repositories\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def get_top_repos(repos: list[dict], n: int = 5, sort_by: str = \"stars\") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get top N repositories sorted by specified field (in descending order).\n",
    "    \n",
    "    Args:\n",
    "        repos: List of repository dictionaries\n",
    "        n: Number of repos to return\n",
    "        sort_by: Field to sort by (\"stars\", \"forks\", \"updated_at\")\n",
    "    \n",
    "    Returns:\n",
    "        Top N repositories\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_tests():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"GITHUB REPOSITORY ANALYZER\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    print(\"Fetching octocat's repositories from GitHub API...\")\n",
    "    repos = fetch_github_user_repos(\"octocat\", token=None)\n",
    "    print(f\"Fetched {len(repos)} repositories\\n\")\n",
    "    \n",
    "    # Test 1: format_repo_summary\n",
    "    print(\"Test 1: format_repo_summary\")\n",
    "    print(\"-\" * 70)\n",
    "    if repos:\n",
    "        # Get the most starred repo\n",
    "        top_repo = max(repos, key=lambda r: r.get(\"stars\", 0))\n",
    "        summary = format_repo_summary(top_repo)\n",
    "        \n",
    "        print(f\"Testing with: {top_repo['name']}\")\n",
    "        print(f\"Result:\\n{summary}\\n\")\n",
    "        \n",
    "        # Assertions\n",
    "        assert top_repo[\"name\"] in summary, \"Name should be in summary\"\n",
    "        assert \"⭐\" in summary, \"Should contain star emoji\"\n",
    "        assert top_repo[\"url\"] in summary, \"URL should be in summary\"\n",
    "        \n",
    "        # Check formatting of stars\n",
    "        if top_repo[\"stars\"] >= 1000:\n",
    "            assert \",\" in summary, \"Stars >= 1000 should have comma separator\"\n",
    "        \n",
    "        print(\"format_repo_summary test passed!\\n\")\n",
    "    \n",
    "    # Test 2: filter_repos_by_language\n",
    "    print(\"Test 2: filter_repos_by_language\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Get all languages present\n",
    "    languages = set(r[\"language\"] for r in repos if r.get(\"language\"))\n",
    "    print(f\"Languages found: {languages}\\n\")\n",
    "    \n",
    "    for language in languages:\n",
    "        filtered = filter_repos_by_language(repos, language)\n",
    "        \n",
    "        # Verify all filtered repos have the correct language\n",
    "        for repo in filtered:\n",
    "            assert repo.get(\"language\") == language, f\"Expected {language}, got {repo.get('language')}\"\n",
    "        \n",
    "        assert len(filtered) > 0, f\"Should find at least one {language} repo\"\n",
    "        print(f\"{language}: Found {len(filtered)} repositories\")\n",
    "    \n",
    "    # Test case insensitivity\n",
    "    if languages:\n",
    "        test_lang = list(languages)[0]\n",
    "        lower_result = filter_repos_by_language(repos, test_lang.lower())\n",
    "        upper_result = filter_repos_by_language(repos, test_lang.upper())\n",
    "        mixed_result = filter_repos_by_language(repos, test_lang)\n",
    "        \n",
    "        assert len(lower_result) == len(upper_result) == len(mixed_result), \\\n",
    "            \"Filtering should be case-insensitive\"\n",
    "        print(f\"Case-insensitive filtering works\\n\")\n",
    "    \n",
    "    print(\"filter_repos_by_language test passed!\\n\")\n",
    "    \n",
    "    # Test 3: get_top_repos by stars\n",
    "    print(\"Test 3: get_top_repos (by stars)\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    n = min(5, len(repos))\n",
    "    top_by_stars = get_top_repos(repos, n=n, sort_by=\"stars\")\n",
    "    \n",
    "    assert len(top_by_stars) == n, f\"Expected {n} repos, got {len(top_by_stars)}\"\n",
    "    \n",
    "    # Verify sorted in descending order\n",
    "    for i in range(len(top_by_stars) - 1):\n",
    "        assert top_by_stars[i][\"stars\"] >= top_by_stars[i + 1][\"stars\"], \\\n",
    "            \"Repos should be sorted by stars in descending order\"\n",
    "    \n",
    "    print(f\"Top {n} repositories by stars:\")\n",
    "    for i, repo in enumerate(top_by_stars, 1):\n",
    "        print(f\"  {i}. {repo['name']} - {repo['stars']:,} ⭐\")\n",
    "    \n",
    "    print(\"\\nget_top_repos (stars) test passed!\\n\")\n",
    "    \n",
    "    # Test 4: get_top_repos by forks\n",
    "    print(\"Test 4: get_top_repos (by forks)\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    top_by_forks = get_top_repos(repos, n=n, sort_by=\"forks\")\n",
    "    \n",
    "    assert len(top_by_forks) == n, f\"Expected {n} repos, got {len(top_by_forks)}\"\n",
    "    \n",
    "    # Verify sorted in descending order\n",
    "    for i in range(len(top_by_forks) - 1):\n",
    "        assert top_by_forks[i][\"forks\"] >= top_by_forks[i + 1][\"forks\"], \\\n",
    "            \"Repos should be sorted by forks in descending order\"\n",
    "    \n",
    "    print(f\"Top {n} repositories by forks:\")\n",
    "    for i, repo in enumerate(top_by_forks, 1):\n",
    "        print(f\"  {i}. {repo['name']} - {repo['forks']:,} forks\")\n",
    "    \n",
    "    print(\"\\nget_top_repos (forks) test passed!\\n\")\n",
    "    \n",
    "    # Test 5: Limiting results\n",
    "    print(\"Test 5: Result limiting\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if len(repos) >= 3:\n",
    "        top_2 = get_top_repos(repos, n=2, sort_by=\"stars\")\n",
    "        assert len(top_2) == 2, f\"Expected 2 repos, got {len(top_2)}\"\n",
    "        print(\"Correctly limits to n repos\")\n",
    "    \n",
    "    # Request more than available\n",
    "    large_n = len(repos) + 100\n",
    "    all_repos = get_top_repos(repos, n=large_n, sort_by=\"stars\")\n",
    "    assert len(all_repos) == len(repos), \\\n",
    "        \"Should return all available repos when n > total repos\"\n",
    "    print(\"Handles n > total repos correctly\")\n",
    "    \n",
    "    print(\"\\nResult limiting test passed!\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ALL TESTS PASSED\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nTested with {len(repos)} repositories from octocat's profile\")\n",
    "    print(f\"Languages tested: {', '.join(sorted(languages))}\")\n",
    "    print(f\"Most starred repo: {top_by_stars[0]['name']} ({top_by_stars[0]['stars']:,} ⭐)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    run_all_tests()\n",
    "except Exception as e:\n",
    "    print(f\"\\nTEST FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_repo_summary(repo: dict) -> str:\n",
    "    \"\"\"\n",
    "    Format a repository summary string.\n",
    "    \n",
    "    Args:\n",
    "        repo: Dictionary with keys: name, description, stars, language, url\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string like:\n",
    "        \"repo-name (Python) - 1,234 ⭐\n",
    "         Description here\n",
    "         https://github.com/user/repo\"\n",
    "    \"\"\"\n",
    "    name = repo.get(\"name\", \"Unknown\")\n",
    "    description = repo.get(\"description\", \"No description provided\")\n",
    "    stars = repo.get(\"stars\", 0)\n",
    "    language = repo.get(\"language\", \"Unknown\")\n",
    "    url = repo.get(\"url\", \"\")\n",
    "    stars_formatted = f\"{stars:,}\"\n",
    "    \n",
    "    # Build the summary string\n",
    "    summary = f\"{name} ({language}) - {stars_formatted} ⭐\\n{description}\\n{url}\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "def filter_repos_by_language(repos: list[dict], language: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Filter repositories by programming language.\n",
    "    \n",
    "    Args:\n",
    "        repos: List of repository dictionaries\n",
    "        language: Programming language to filter by (case-insensitive)\n",
    "    \n",
    "    Returns:\n",
    "        Filtered list of repositories\n",
    "    \"\"\"\n",
    "    language_lower = language.lower()\n",
    "    return [\n",
    "        repo for repo in repos \n",
    "        if repo.get(\"language\") and repo.get(\"language\").lower() == language_lower\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_top_repos(repos: list[dict], n: int = 5, sort_by: str = \"stars\") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get top N repositories sorted by specified field.\n",
    "    \n",
    "    Args:\n",
    "        repos: List of repository dictionaries\n",
    "        n: Number of repos to return\n",
    "        sort_by: Field to sort by (\"stars\", \"forks\", \"updated_at\")\n",
    "    \n",
    "    Returns:\n",
    "        Top N repositories\n",
    "    \"\"\"\n",
    "    # Sort repositories by the specified field in descending order\n",
    "    sorted_repos = sorted(\n",
    "        repos,\n",
    "        key=lambda repo: repo.get(sort_by, 0),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Return top N\n",
    "    return sorted_repos[:n]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
