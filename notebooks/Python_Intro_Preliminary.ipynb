{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG8CxJlidUSm"
   },
   "source": [
    "## Variables and basic types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT92Jq3_fMGk"
   },
   "source": [
    "### String formatting\n",
    "Python offers several ways to format strings. You'll use these constantly when building prompts, logging, and displaying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ns1ye8TZdSOL",
    "outputId": "d909f760-bacc-4ec5-cdbe-0584985931e2"
   },
   "outputs": [],
   "source": [
    "# F-strings\n",
    "provider = \"claude\"\n",
    "model = \"sonnet-4.5\"\n",
    "message = f\"Using {provider} with model {model}\"\n",
    "print(message)  # Using claude with model sonnet-4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tON-wh3Dfe8P",
    "outputId": "ae7a3f7e-0cd4-4ec4-aeb7-93f9372917ba"
   },
   "outputs": [],
   "source": [
    "# Multi-line f-strings, common for building prompts\n",
    "name = str(input(\"Give a cool name to your AI assistant: \"))\n",
    "user_input = str(input(\"Ask your AI assistant something: \"))\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant named {name}.\n",
    "Your task is to answer the following query:\n",
    "{user_input}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpdh1AAXdZLu"
   },
   "source": [
    "### Dictionaries and lists\n",
    "These structures map directly to JSON, which you'll use for API requests and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQ4YELgxgEtJ",
    "outputId": "ff4e4a23-9cc1-4e4e-b929-e01f081c8214"
   },
   "outputs": [],
   "source": [
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What is the weather today?\"\n",
    "}\n",
    "\n",
    "# Accessing values\n",
    "print(user_message[\"role\"])\n",
    "print(user_message.get(\"content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JpSCyLyNmmp",
    "outputId": "aea6ea72-fd4e-4593-b44e-b32dc7af4344"
   },
   "outputs": [],
   "source": [
    "# Nested dictionaries (common in API payloads)\n",
    "api_request = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "models = [\"gpt-4\", \"claude-3\", \"llama-2\"]\n",
    "print(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZEmaf0Mf7hm",
    "outputId": "376e273f-0c11-4060-a430-6b8b33fd7964"
   },
   "outputs": [],
   "source": [
    "# Adding items\n",
    "models.append(\"gemini-pro\")\n",
    "\n",
    "# Iterating\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pqyzF1fNx14"
   },
   "outputs": [],
   "source": [
    "# List of dictionaries (common pattern)\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hello! How can I help?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPeQaWlGdfDz"
   },
   "source": [
    "## Functions and control flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQJ_KgEHg1HQ"
   },
   "source": [
    "### Function definitions\n",
    "Functions in Python are straightforward. You'll write them to organize API calls, process responses, and build reusable logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "URsiuUwodjod",
    "outputId": "b3f2d099-2a7b-461d-ce9d-1f0ca186d929"
   },
   "outputs": [],
   "source": [
    "# Basic function\n",
    "def create_system_prompt(role: str) -> str: # role: str is a type hint for the input, the -> indicates the function return type\n",
    "    return f\"You are a {role}. Please assist the user.\"\n",
    "\n",
    "create_system_prompt(\"helpful assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rErgUrWLN2S2",
    "outputId": "ccd08867-7063-473f-fd49-8ad6325a842d"
   },
   "outputs": [],
   "source": [
    "# Function with multiple parameters and default values\n",
    "def call_llm(prompt: str, model: str = \"gpt-4\", temperature: float = 0.7) -> dict:\n",
    "    \"\"\"\n",
    "    Docstrings describe what the function does.\n",
    "    They're optional but helpful for complex functions.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "\n",
    "# Using the function\n",
    "response = call_llm(\"What is AI?\")  # uses defaults: model = \"gpt-4\", temperature = 0.7\n",
    "response = call_llm(\"What is AI?\", model=\"claude-3\", temperature=0.5)  # overrides defaults\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-ehT7RjN9_N",
    "outputId": "49dff0b9-d442-4a60-d365-69efb741b2dc"
   },
   "outputs": [],
   "source": [
    "mock_response = {\n",
    "  \"id\": \"chatcmpl-8x7k2Pm9qK3j5L8n4Yw6Xz\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1729512345,\n",
    "  \"model\": \"gpt-4\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hello! I'm an AI assistant. How can I help you today?\"\n",
    "      },\n",
    "      \"finish_reason\": \"stop\"\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 12,\n",
    "    \"completion_tokens\": 15,\n",
    "    \"total_tokens\": 27\n",
    "  }\n",
    "}\n",
    "\n",
    "# Functions can return multiple values (as a tuple)\n",
    "def parse_response(api_response: dict) -> tuple[str, int]:\n",
    "    content = api_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    tokens = api_response[\"usage\"][\"total_tokens\"]\n",
    "    return content, tokens\n",
    "\n",
    "# Unpacking the return values\n",
    "text, token_count = parse_response(mock_response)\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Tokens: {token_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhCSwV6dhE2H"
   },
   "source": [
    "### Conditional logic\n",
    "Use conditionals to handle different scenarios in your application logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "g9Agzo2UQxsT",
    "outputId": "ab19e424-2b95-4748-daaf-b8055137e096"
   },
   "outputs": [],
   "source": [
    "# Basic if/else\n",
    "def get_model_tier(model_name: str) -> str:\n",
    "    if model_name.startswith(\"gpt\"):\n",
    "        return \"premium\"\n",
    "    else:\n",
    "        return \"standard\"\n",
    "\n",
    "get_model_tier(\"gpt-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5t1TccgARGWW",
    "outputId": "130ea826-8f28-4695-9bb6-4ef22afac4bb"
   },
   "outputs": [],
   "source": [
    "# if/elif/else for multiple conditions\n",
    "def calculate_cost(tokens: int, model: str) -> float:\n",
    "    if model == \"gpt-4\":\n",
    "        rate = 0.03\n",
    "    elif model == \"gpt-3.5-turbo\":\n",
    "        rate = 0.002\n",
    "    elif model == \"claude-3\":\n",
    "        rate = 0.015\n",
    "    else:\n",
    "        rate = 0.001  # default rate\n",
    "\n",
    "    return tokens * rate / 1000\n",
    "\n",
    "calculate_cost(1000, \"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LrPYEsy3RJMB",
    "outputId": "5474e5c1-ec8b-4400-e666-fa2eb9708c01"
   },
   "outputs": [],
   "source": [
    "# Checking if values exist (common with API responses)\n",
    "def extract_content(response: dict) -> str:\n",
    "    if \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return \"No response available\"\n",
    "\n",
    "extract_content(mock_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kM1CkwJWS9Si",
    "outputId": "32bccac6-0eaf-48cb-9e3b-1b90dcfbab2f"
   },
   "outputs": [],
   "source": [
    "# Boolean conditions\n",
    "def should_retry(status_code: int, attempt: int) -> bool:\n",
    "    if status_code == 429 and attempt < 3:  # Rate limited, under retry limit\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "should_retry(429, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tk1waBsdnGh",
    "outputId": "1d4dd8e6-676b-4ef5-e02b-3eba161d4676"
   },
   "outputs": [],
   "source": [
    "response = {\n",
    "    \"status_code\": 200,\n",
    "    \"data\": {\"message\": \"Request successful\"}\n",
    "}\n",
    "# Ternary operator (inline if/else)\n",
    "status = \"success\" if response['status_code'] == 200 else \"error\"\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "u6J0NkDnTL7v",
    "outputId": "4625816c-8bc3-4c6f-90f1-0ec68a5d9507"
   },
   "outputs": [],
   "source": [
    "# Checking for None\n",
    "def process_data(data: dict | None) -> str:\n",
    "    if data is None:\n",
    "        return \"No data provided\"\n",
    "\n",
    "    return data.get(\"result\", \"No result found\")\n",
    "\n",
    "process_data({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOOiS8xjhYGs"
   },
   "source": [
    "### List comprehensions\n",
    "List comprehensions provide a concise way to transform and filter data. You'll use them frequently when processing API responses or preparing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Gy3uMItZinz",
    "outputId": "f0517d6c-38d1-4fb9-ce15-19bb592ac30e"
   },
   "outputs": [],
   "source": [
    "# Example: extracting specific fields\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"user\", \"content\": \"How are you?\"}\n",
    "]\n",
    "\n",
    "# Extract just the content from each message\n",
    "print([msg[\"content\"] for msg in messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CHgrldbZt9e",
    "outputId": "f2287088-75b8-4e97-b48d-575aca58abf6"
   },
   "outputs": [],
   "source": [
    "# List comprehension with filtering\n",
    "user_messages = [msg for msg in messages if msg[\"role\"] == \"user\"]\n",
    "\n",
    "print(user_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqC4pyYwZ8KF",
    "outputId": "54fdf9e5-723b-4eae-fc92-27b48a47f301"
   },
   "outputs": [],
   "source": [
    "# Transform and filter together\n",
    "user_contents = [msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\"]\n",
    "\n",
    "print(user_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZugZyuZaGk5",
    "outputId": "6b907cf5-6f4f-4d4f-a5e6-0ab7a08e4d58"
   },
   "outputs": [],
   "source": [
    "# Working with strings\n",
    "models = [\"gpt-4-turbo\", \"gpt-3.5-turbo\", \"claude-3-opus\"]\n",
    "\n",
    "gpt_models = [model for model in models if model.startswith(\"gpt\")]\n",
    "uppercase_models = [model.upper() for model in models]\n",
    "\n",
    "print(f\"GPT models: {gpt_models} \\nUppercase models: {uppercase_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GA5YqbPNa7A5",
    "outputId": "2d0979a3-25bf-480f-834d-508f95b592a3"
   },
   "outputs": [],
   "source": [
    "api_responses = [\n",
    "    {\"id\": 1, \"tokens\": 150, \"cost\": 0.003},\n",
    "    {\"id\": 2, \"tokens\": 200, \"cost\": 0.004},\n",
    "    {\"id\": 3, \"tokens\": 100, \"cost\": 0.002}\n",
    "]\n",
    "\n",
    "# Extract total tokens\n",
    "total_tokens = sum([resp[\"tokens\"] for resp in api_responses])\n",
    "\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4eNX8FgJauoD",
    "outputId": "b07994e6-8685-4b1d-bf86-e0be6af56c35"
   },
   "outputs": [],
   "source": [
    "# Create simplified objects\n",
    "summaries = [\n",
    "    {\"id\": resp[\"id\"], \"tokens\": resp[\"tokens\"]}\n",
    "    for resp in api_responses\n",
    "]\n",
    "\n",
    "print(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7_SULh8haPa",
    "outputId": "a987830c-42b2-4ef4-eec7-aa62c115af69"
   },
   "outputs": [],
   "source": [
    "# Dictionary comprehension. Convert list to dictionary\n",
    "token_map = {resp[\"id\"]: resp[\"tokens\"] for resp in api_responses}\n",
    "\n",
    "print(token_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JkbGDRodnZz"
   },
   "source": [
    "## Working with external libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSvuhEn4kxQz"
   },
   "source": [
    "### Installing packages\n",
    "Python's ecosystem relies on external packages. You can use any package present in the Python Package index (https://pypi.org/). \n",
    "You'll install them using `pip` (https://github.com/pypa/pip) or `uv` (https://github.com/astral-sh/uv). This setup already contains the `requests` library from the `requirements.txt` (you can inspect the Dockerfile for details on the installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQAmOGpbkxBh",
    "outputId": "b7b95b24-4020-4165-bf74-d64d48392375"
   },
   "outputs": [],
   "source": [
    "!uv pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gsb56W9adrSB"
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KX6BkSE5dxaz",
    "outputId": "072a7257-8d19-46d3-8512-8b132ddcb5ae"
   },
   "outputs": [],
   "source": [
    "# Make a GET request to a public API\n",
    "response = requests.get(\"https://api.github.com/users/github\")\n",
    "\n",
    "status = \"success\" if response.status_code == 200 else \"error\"\n",
    "\n",
    "print(f\"Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18Mw5IticEUQ",
    "outputId": "46fd3652-4c40-4681-be3e-71cf34913be6"
   },
   "outputs": [],
   "source": [
    "# Parse the JSON response\n",
    "if status == \"success\":\n",
    "    data = response.json()\n",
    "    print(f\"\\nUsername: {data['login']}\")\n",
    "    print(f\"Name: {data['name']}\")\n",
    "    print(f\"Public repos: {data['public_repos']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eJti318d4_3"
   },
   "source": [
    "## Intro to classes\n",
    "\n",
    "Classes let you create custom objects with their own data and behavior. You won't write many classes from scratch, but you'll use them constantly when working with objects provided by the external packages you import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0VFL7kuqC_W"
   },
   "source": [
    "### Basic class structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8fnZN-iZOJc"
   },
   "source": [
    "`__init__` sets up the object when you create it. Methods are functions that operate on the object's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEAVYBJUd9Yt"
   },
   "outputs": [],
   "source": [
    "# Define a class\n",
    "class ChatMessage:\n",
    "    def __init__(self, role: str, content: str):\n",
    "        \"\"\"__init__ runs when you create a new instance\"\"\"\n",
    "        self.role = role\n",
    "        self.content = content\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        \"\"\"Methods are functions that belong to the class\"\"\"\n",
    "        return {\n",
    "            \"role\": self.role,\n",
    "            \"content\": self.content\n",
    "        }\n",
    "\n",
    "    def is_user_message(self) -> bool:\n",
    "        return self.role == \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D41tlbPORg-Q",
    "outputId": "0e9388e4-263b-4109-e93d-8c2aa158ce3e"
   },
   "outputs": [],
   "source": [
    "# Create instances (objects) of the class\n",
    "msg1 = ChatMessage(role=\"user\", content=\"Hello\")\n",
    "msg2 = ChatMessage(role=\"assistant\", content=\"Hi there!\")\n",
    "\n",
    "# Access attributes\n",
    "print(msg1.role)\n",
    "print(msg1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qz08XxJvRk7B",
    "outputId": "30dfe58d-5ff9-48a5-c4d1-74c4fdb8344d"
   },
   "outputs": [],
   "source": [
    "# Call methods\n",
    "print(msg1.to_dict())\n",
    "print(msg1.is_user_message())\n",
    "print(msg2.is_user_message())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss_yLji4qBP-"
   },
   "source": [
    "### Example: Pydantic data models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq476IM1Y0uJ"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydantic classes validate data automatically\n",
    "class ChatRequest(BaseModel):\n",
    "    message: str\n",
    "    model: str = \"gpt-4\"\n",
    "    temperature: float = Field(default=0.7, ge=0, le=2)\n",
    "\n",
    "# Create instance - Pydantic validates the data\n",
    "request = ChatRequest(message=\"What is AI?\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kW-96vU1q1gA",
    "outputId": "68e2643f-f1ff-49b7-a76b-b7efa8d6d240"
   },
   "outputs": [],
   "source": [
    "# Access attributes\n",
    "print(request.message)\n",
    "print(request.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVpEoF1mZCMH",
    "outputId": "b6b6c275-8e06-4ea5-a04c-21818b768eca"
   },
   "outputs": [],
   "source": [
    "# Convert to dict (useful for API calls)\n",
    "print(request.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GslSE11rGtZ"
   },
   "source": [
    "In this course, you'll mostly use pre-built classes from libraries (Pydantic models, LangChain classes, etc.) rather than writing your own. Understanding how to create instances and call methods is what matters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
